import { api } from '../../convex/_generated/api';

export interface AIResponse {
  response: string;
  contextsUsed: number;
  sourcesReferenced: string[];
  processingTimeMs: number;
}

export class AIService {

  // Generate response with ALL available context types
  static async generateResponse(
    userQuestion: string,
    canvasId: string,
    hasDocuments: boolean = false,
    ragieAction?: any, // useAction(api.ragie.generateResponse)
    groqAction?: any, // useAction(api.groq.generateResponse)
    youtubeContext?: string, // YouTube video context
    webContentContext?: string, // Website content from Jina Reader
    textNodesContext?: string // Text nodes content
  ): Promise<AIResponse> {

    const startTime = Date.now();

    // Strategy: Combine all available contexts, prioritizing richer content
    // NEVER fail - always provide an answer

    // Build combined context from all sources
    const contextSources: string[] = [];
    const contextParts: string[] = [];
    let totalContexts = 0;

    // Add YouTube video context
    if (youtubeContext) {
      contextParts.push(`YOUTUBE VIDEO INFORMATION:\n${youtubeContext}`);
      contextSources.push('YouTube Video');
      totalContexts++;
    }

    // Add web content context
    if (webContentContext) {
      contextParts.push(`WEBSITE CONTENT:\n${webContentContext}`);
      contextSources.push('Web Article');
      totalContexts++;
    }

    // Add text nodes context
    if (textNodesContext) {
      contextParts.push(`TEXT NOTES:\n${textNodesContext}`);
      contextSources.push('Text Notes');
      totalContexts++;
    }

    // TIER 0: Use combined node contexts (YouTube + Web + Text)
    if (contextParts.length > 0 && groqAction) {
      try {
        console.log(`üåê Using ${totalContexts} node context(s): ${contextSources.join(', ')}`);

        const combinedContext = contextParts.join('\n\n---\n\n');

        const contextualPrompt = `Based on the following information from the user's canvas, answer their question accurately.

${combinedContext}

QUESTION: ${userQuestion}

Provide a detailed answer based on the information above. Reference the specific sources when relevant.`;

        const groqResponse = await groqAction({
          query: contextualPrompt,
          hasDocuments: true,
        });

        console.log(`‚úÖ Response generated with ${totalContexts} node context(s)`);
        return {
          response: groqResponse.response,
          contextsUsed: totalContexts,
          sourcesReferenced: contextSources,
          processingTimeMs: Date.now() - startTime,
        };
      } catch (error) {
        console.warn('‚ö†Ô∏è Node context failed:', error);
        // Continue to Ragie
      }
    }

    // TIER 1: Try Ragie with document context
    if (hasDocuments && ragieAction && groqAction) {
      try {
        console.log('üß† Retrieving context from Ragie...');

        const ragieResponse = await ragieAction({
          query: userQuestion,
          filter: {
            scope: canvasId,
            canvasId,
          },
        });

        const chunks = ragieResponse?.chunks || [];
        const sources = ragieResponse?.sources || [];

        // If we have context chunks, use them with Groq
        if (chunks.length > 0) {
          console.log('‚úÖ Ragie found', chunks.length, 'relevant chunks');

          // Build context from chunks
          const context = chunks
            .map((chunk: any, idx: number) =>
              `[Context ${idx + 1} from ${chunk.document_name}]\n${chunk.text}`
            )
            .join('\n\n---\n\n');

          const contextualPrompt = `Based on the following context from the user's uploaded documents, answer their question accurately and cite the sources.

CONTEXT:
${context}

QUESTION: ${userQuestion}

Provide a detailed answer based on the context above. Reference the specific documents and be precise.`;

          // Generate response with context using Groq
          const groqResponse = await groqAction({
            query: contextualPrompt,
            hasDocuments: true,
          });

          console.log('‚úÖ Groq generated contextual response');
          return {
            response: groqResponse.response,
            contextsUsed: chunks.length,
            sourcesReferenced: sources,
            processingTimeMs: Date.now() - startTime,
          };
        }

        console.log('‚ö†Ô∏è Ragie found no relevant chunks');
      } catch (ragieError) {
        console.warn('‚ö†Ô∏è Ragie failed:', ragieError);
        // Continue to general Gemini
      }
    }

    // TIER 2: Try Groq AI via Convex action
    if (groqAction) {
      try {
        console.log('üí¨ Calling Groq via Convex...');

        const groqResponse = await groqAction({
          query: userQuestion,
          hasDocuments: hasDocuments,
        });

        console.log('‚úÖ Groq response received');
        return {
          response: groqResponse.response,
          contextsUsed: 0,
          sourcesReferenced: [],
          processingTimeMs: Date.now() - startTime,
        };

      } catch (groqError) {
        console.error('‚ùå Groq failed:', groqError);
        // Continue to ultimate fallback
      }
    } else {
      console.warn('‚ö†Ô∏è Groq action not provided');
    }

    // TIER 3: Ultimate fallback - ALWAYS provide a response
    console.log('üõü Using fallback response (all AI services failed)');
    return {
      response: this.getFallbackResponse(userQuestion, hasDocuments),
      contextsUsed: 0,
      sourcesReferenced: [],
      processingTimeMs: Date.now() - startTime,
    };
  }

  // Fallback responses when all AI services fail
  private static getFallbackResponse(question: string, hasDocuments: boolean): string {
    const lowerQuestion = question.toLowerCase();

    // Handle greetings
    if (lowerQuestion.match(/^(hi|hello|hey|greetings)/)) {
      return hasDocuments
        ? "Hello! I'm Neuron AI. I can see you have documents uploaded. Ask me anything about them, or any general questions!"
        : "Hello! I'm Neuron AI, your learning assistant. Upload some documents and I'll help you understand them, or ask me anything!";
    }

    // Handle help requests
    if (lowerQuestion.includes('help') || lowerQuestion.includes('how') && lowerQuestion.includes('work')) {
      return "I'm Neuron AI! I can help you organize knowledge and answer questions. Upload documents and I'll provide contextual answers based on their content. Right now I'm experiencing some technical difficulties with my AI backend, but I'm here to help!";
    }

    // Handle document questions
    if (hasDocuments && (lowerQuestion.includes('document') || lowerQuestion.includes('what') || lowerQuestion.includes('explain'))) {
      return "I can see you have documents uploaded! I'm experiencing some technical issues connecting to my AI services right now. Please check that your internet connection is stable, or try asking again in a moment. Meanwhile, you can review your documents on the canvas.";
    }

    // General fallback
    return "I apologize, but I'm having trouble connecting to my AI services right now. This could be due to API configuration or network issues. Please:\n\n1. Check your internet connection\n2. Refresh the page\n3. Try again in a moment\n\nI'm still here to help once the connection is restored!";
  }

  // Test Ragie connection
  static async testRagieConnection(testAction: any): Promise<boolean> {
    try {
      // Try a simple test query through Convex
      await testAction({
        query: 'test',
      });
      return true;
    } catch (error) {
      console.error('Ragie connection test failed:', error);
      return false;
    }
  }
}

export default AIService;
